{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca641f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3 \n",
    "\n",
    "my_session = boto3.session.Session()\n",
    "my_region = my_session.region_name\n",
    "client = boto3.client(\"sts\")\n",
    "account_id = client.get_caller_identity()[\"Account\"]\n",
    "algorithm_name = \"informer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3bd3fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230755935769\n",
      "us-west-2\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "base_img:763104351884.dkr.ecr.us-west-2.amazonaws.com/pytorch-training:1.7.1-gpu-py36-cu110-ubuntu18.04\n",
      "Sending build context to Docker daemon  615.2MB\n",
      "Step 1/7 : ARG BASE_IMG=${BASE_IMG}\n",
      "Step 2/7 : FROM ${BASE_IMG}\n",
      " ---> 910c070760f2\n",
      "Step 3/7 : ENV PATH=\"/opt/ml/code:${PATH}\"\n",
      " ---> Running in 4a9f8cb3f466\n",
      "Removing intermediate container 4a9f8cb3f466\n",
      " ---> 85c2855d4fc8\n",
      "Step 4/7 : WORKDIR /opt/program\n",
      " ---> Running in d8bc5c04590c\n",
      "Removing intermediate container d8bc5c04590c\n",
      " ---> 74d4c6a37cfc\n",
      "Step 5/7 : RUN cp /changehostname.c /opt/program/\n",
      " ---> Running in ac811fa587b8\n",
      "Removing intermediate container ac811fa587b8\n",
      " ---> 46be5a3a96c6\n",
      "Step 6/7 : COPY . /opt/program/\n",
      "failed to copy files: failed to copy directory: Error processing tar file(exit status 1): write /results/informer_ETTm1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_test_1/true.npy: no space left on device\n",
      "The push refers to repository [230755935769.dkr.ecr.us-west-2.amazonaws.com/informer]\n",
      "\n",
      "\u001b[1B27f474d8: Preparing \n",
      "\u001b[1B84debad3: Preparing \n",
      "\u001b[1B615fb1ec: Preparing \n",
      "\u001b[1B426c5cb3: Preparing \n",
      "\u001b[1Be81c04ac: Preparing \n",
      "\u001b[1Baa20b119: Preparing \n",
      "\u001b[1B62d7b191: Preparing \n",
      "\u001b[1B621c0763: Preparing \n",
      "\u001b[1B55e0088c: Preparing \n",
      "\u001b[1Bf702dd6c: Preparing \n",
      "\u001b[1B4f900f31: Preparing \n",
      "\u001b[1Bb1eec580: Preparing \n",
      "\u001b[1B1d1bff9f: Preparing \n",
      "\u001b[1B4e98599b: Preparing \n",
      "\u001b[1B355c3b7e: Preparing \n",
      "\u001b[1B1a00d0a6: Preparing \n",
      "\u001b[11B2d7b191: Waiting g \n",
      "\u001b[11B21c0763: Waiting g \n",
      "\u001b[11B5e0088c: Waiting g \n",
      "\u001b[8B1d1bff9f: Waiting g \n",
      "\u001b[8B4e98599b: Waiting g \n",
      "\u001b[7B1a00d0a6: Waiting g \n",
      "\u001b[9B355c3b7e: Waiting g \n",
      "\u001b[5B0f52b878: Waiting g \n",
      "\u001b[1B0bcc6897: Preparing \n",
      "\u001b[4Bce2a51ec: Waiting g \n",
      "\u001b[1Bc5356ba1: Preparing \n",
      "\u001b[3Bcdf6d5f2: Waiting g \n",
      "\u001b[3Bc5356ba1: Waiting g \n",
      "\u001b[1Ba7c9e3d1: Preparing \n",
      "\u001b[1B4dce1444: Preparing \n",
      "\u001b[2B4dce1444: Waiting g \n",
      "\u001b[2B30bcc944: Waiting g \n",
      "\u001b[1B4df0ad6c: Preparing \n",
      "\u001b[2B4df0ad6c: Waiting g \n",
      "\u001b[1B02706667: Layer already exists \u001b[30A\u001b[2K\u001b[31A\u001b[2K\u001b[23A\u001b[2K\u001b[18A\u001b[2K\u001b[12A\u001b[2K\u001b[9A\u001b[2K\u001b[2A\u001b[2Klatest: digest: sha256:eb97966186667cb285d9415f51a58b12ca462914bbea68bc25cc375f7e60268d size: 7885\n"
     ]
    }
   ],
   "source": [
    "!./build_and_push.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b62bc12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'230755935769.dkr.ecr.us-west-2.amazonaws.com/informer'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_uri=f\"{account_id}.dkr.ecr.{my_region}.amazonaws.com/{algorithm_name}\"\n",
    "image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065333c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'ETDataset'...\n",
      "remote: Enumerating objects: 187, done.\u001b[K\n",
      "remote: Counting objects: 100% (187/187), done.\u001b[K\n",
      "remote: Compressing objects: 100% (184/184), done.\u001b[K\n",
      "remote: Total 187 (delta 66), reused 13 (delta 2), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (187/187), 3.85 MiB | 10.36 MiB/s, done.\n",
      "Resolving deltas: 100% (66/66), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/zhouhaoyi/ETDataset.git "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202b2812",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p input\n",
    "!mkdir -p input/data\n",
    "!mkdir -p input/data/training\n",
    "!mv ETDataset/ETT-small/*.csv input/data/training/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f879bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker \n",
    "from sagemaker import get_execution_role\n",
    "session = sagemaker.session.Session()\n",
    "bucket = session.default_bucket()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a5c3c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-230755935769/data/ETH'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_path = f\"s3://{bucket}/data/ETH\"\n",
    "s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e18b51b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: input/data/training/ETTh1.csv to s3://sagemaker-us-west-2-230755935769/data/ETH/ETTh1.csv\n",
      "upload: input/data/training/ETTh2.csv to s3://sagemaker-us-west-2-230755935769/data/ETH/ETTh2.csv\n",
      "upload: input/data/training/ETTm2.csv to s3://sagemaker-us-west-2-230755935769/data/ETH/ETTm2.csv\n",
      "upload: input/data/training/ETTm1.csv to s3://sagemaker-us-west-2-230755935769/data/ETH/ETTm1.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive ./input/data/training/ $s3_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8bb7cd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'informer-1623929069'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = datetime.timestamp(now)\n",
    "job_name = \"informer-{}\".format(str(int(timestamp))) \n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6147d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sagemaker.local.local_session.LocalSession object at 0x7f7db12315f8>\n"
     ]
    }
   ],
   "source": [
    "mode = 'local'\n",
    "if mode == 'local':\n",
    "    csess = sagemaker.local.LocalSession()\n",
    "else:    \n",
    "    csess = session\n",
    "\n",
    "print(csess)\n",
    "estimator = sagemaker.estimator.Estimator( \n",
    "                        role=role,\n",
    "                        image_uri=image_uri,\n",
    "                        instance_count=1,\n",
    "#                         instance_type='local_gpu',\n",
    "                        instance_type='ml.p2.xlarge',\n",
    "                        sagemaker_session=csess,\n",
    "                        volume_size=100, \n",
    "                        debugger_hook_config=False\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90173d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 8nkcmxorku-algo-1-yrbtw ... \n",
      "Creating 8nkcmxorku-algo-1-yrbtw ... done\n",
      "Attaching to 8nkcmxorku-algo-1-yrbtw\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m {'model': 'informer', 'data': 'ETTh1', 'root_path': './data/ETT/', 'data_path': 'ETTh1.csv', 'features': 'M', 'target': 'OT', 'freq': 'h', 'seq_len': 96, 'label_len': 48, 'pred_len': 24, 'enc_in': 7, 'dec_in': 7, 'c_out': 7, 'd_model': 512, 'n_heads': 8, 'e_layers': 2, 'd_layers': 1, 'd_ff': 2048, 'factor': 5, 'distil': True, 'dropout': 0.05, 'attn': 'prob', 'embed': 'timeF', 'activation': 'gelu', 'output_attention': False, 'num_workers': 0, 'itr': 2, 'train_epochs': 6, 'batch_size': 32, 'patience': 3, 'learning_rate': 0.0001, 'des': 'test', 'loss': 'mse', 'lradj': 'type1', 'use_gpu': True, 'gpu': 0}\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Args in experiment:\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m namespace(activation='gelu', attn='prob', batch_size=32, c_out=7, d_ff=2048, d_layers=1, d_model=512, data='ETTh1', data_path='ETTh1.csv', dec_in=7, des='test', distil=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=7, factor=5, features='M', freq='h', gpu=0, itr=2, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='informer', n_heads=8, num_workers=0, output_attention=False, patience=3, pred_len=24, root_path='/opt/ml/input/data/training/', seq_len=96, target='OT', train_epochs=6, use_gpu=False)\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Use CPU\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m >>>>>>>start training : informer_ETTh1_ftM_sl96_ll48_pl24_dm512_nh8_el2_dl1_df2048_atprob_fc5_ebtimeF_dtTrue_test_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m train 8521\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m val 2857\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m test 2857\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m [2021-06-17 11:24:45.811 6c48983bcf96:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m [2021-06-17 11:24:45.857 6c48983bcf96:1 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 100, epoch: 1 | loss: 0.4404010\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 0.9716s/iter; left time: 1454.4626s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 200, epoch: 1 | loss: 0.3037143\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 0.9616s/iter; left time: 1343.3193s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Epoch: 1, Steps: 266 | Train Loss: 0.3886451 Vali Loss: 0.6787355 Test Loss: 0.6437731\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Validation loss decreased (inf --> 0.678735).  Saving model ...\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Updating learning rate to 0.0001\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 100, epoch: 2 | loss: 0.2620311\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 2.2433s/iter; left time: 2761.4489s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 200, epoch: 2 | loss: 0.2736038\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 0.9495s/iter; left time: 1073.8768s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Epoch: 2, Steps: 266 | Train Loss: 0.2585521 Vali Loss: 0.6343434 Test Loss: 0.5738224\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Validation loss decreased (0.678735 --> 0.634343).  Saving model ...\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Updating learning rate to 5e-05\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 100, epoch: 3 | loss: 0.1812348\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 2.1994s/iter; left time: 2122.3887s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 200, epoch: 3 | loss: 0.1941046\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 0.9261s/iter; left time: 801.0907s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Epoch: 3, Steps: 266 | Train Loss: 0.2046680 Vali Loss: 0.6206865 Test Loss: 0.5919083\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Validation loss decreased (0.634343 --> 0.620687).  Saving model ...\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Updating learning rate to 2.5e-05\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 100, epoch: 4 | loss: 0.1824868\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 2.1722s/iter; left time: 1518.3634s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 200, epoch: 4 | loss: 0.2067304\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 0.9145s/iter; left time: 547.7985s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Epoch: 4, Steps: 266 | Train Loss: 0.1780423 Vali Loss: 0.6347475 Test Loss: 0.6842171\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m EarlyStopping counter: 1 out of 3\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m Updating learning rate to 1.25e-05\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 100, epoch: 5 | loss: 0.1518245\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 2.1882s/iter; left time: 947.4695s\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \titers: 200, epoch: 5 | loss: 0.1598473\n",
      "\u001b[36m8nkcmxorku-algo-1-yrbtw |\u001b[0m \tspeed: 0.9093s/iter; left time: 302.8103s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-a140baadceff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0ms3_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \"\"\"\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config, environment, retry_strategy)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m             \u001b[0;31m# _stream_output() doesn't have the command line. We will handle the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mexit_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimator.fit(inputs={\"training\":s3_path}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10321664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
